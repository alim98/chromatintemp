{"version":1,"resource":"vscode-remote://ssh-remote%2Bs_01jtz4dfc5tqsyqw0tv1w86v7n@ssh.lightning.ai/teamspace/studios/this_studio/dataloader/lowres_image_dataloader.py","entries":[{"id":"MuUg.py","source":"Chat Edit: 'in this section, in this file i dont want to load samples from csv, instaed, my structure is like \nlow_res_dataset/centrifugal/1615/raw/0001.tif\nlow_res_dataset/<class_name>/<sample name >/raw/<slice number >.tif\n'","timestamp":1747478522053},{"id":"pKxK.py","timestamp":1747478588498},{"id":"N1SP.py","source":"Chat Edit: 'i removed csv section, and jsut have directory based code, now my low res directory is already low resolution images, and doesnt need to down sample, so we can use directly without down sampling '","timestamp":1747478692322},{"id":"PcVU.py","timestamp":1747478902018},{"id":"cjBV.py","timestamp":1747478978774},{"id":"u03S.py","timestamp":1747478989790},{"id":"Dj2f.py","timestamp":1747479448786},{"id":"L57N.py","timestamp":1747479461638},{"id":"1Anr.py","timestamp":1747482043101},{"id":"g6Z9.py","timestamp":1747482121449},{"id":"SR48.py","timestamp":1747482139477},{"id":"Mo1b.py","timestamp":1747482223730},{"id":"lijh.py","timestamp":1747482250298},{"id":"wasd.py","source":"undoRedo.source","timestamp":1747482266430},{"id":"RZv1.py","timestamp":1747482273678},{"id":"3WlT.py","timestamp":1747482286570},{"id":"BmGz.py","timestamp":1747482301178},{"id":"7wzk.py","source":"Chat Edit: 'yes please '","timestamp":1747482431174},{"id":"Xudq.py","timestamp":1747482483886},{"id":"ubdn.py","source":"Chat Edit: 'Error processing window for sample 2293: default_transform() takes 1 positional argument but 2 were given'","timestamp":1747482537722},{"id":"wI8E.py","source":"Chat Edit: '\nLoading samples from directory structure: low_res_dataset\nTotal number of samples to process: 612\nDataset size: 612\nTraceback (most recent call last):\n  File \"dataloader/lowres_image_dataloader.py\", line 301, in <module>\n    for batch in dataloader:\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n    data = self._next_data()\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\n    return self._process_data(data)\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\n    data.reraise()\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/_utils.py\", line 705, in reraise\n    raise exception\nRuntimeError: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 316, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 154, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 154, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 141, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 212, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n\n⚡ main ~ '","timestamp":1747482627834},{"id":"G96J.py","source":"Chat Edit: '\nLoading samples from directory structure: low_res_dataset\nTotal number of samples to process: 612\nDataset size: 612\nTraceback (most recent call last):\n  File \"dataloader/lowres_image_dataloader.py\", line 304, in <module>\n    for batch in dataloader:\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n    data = self._next_data()\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\n    return self._process_data(data)\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\n    data.reraise()\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/_utils.py\", line 705, in reraise\n    raise exception\nRuntimeError: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 316, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 154, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 154, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 141, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 213, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [80, 1, 60, 67] at entry 0 and [80, 1, 75, 106] at entry 1\n\n⚡ main ~ '","timestamp":1747482707870}]}