# Configuration for training the shape model with our custom dataloaders
experiment_dir: "experiments/shape_model"
device: "cpu" # changed from "cuda" as the PyTorch installation doesn't have CUDA enabled

# Data configuration
data:
  root_dir: "nuclei_sample_1a_v1"
  class_csv_path: "chromatin_classes_and_samples.csv"
  num_points: 1024
  cache_dir: data/mesh_cache
  precomputed_dir: null # Set to a directory path if you have precomputed meshes

# Loader configuration
loader:
  batch_size: 8
  shuffle: true
  num_workers: 0

# Model configuration
model:
  name: "DeepGCN"
  kwargs:
    in_channels: 6
    channels: 64
    out_channels: 64
    k: 12
    norm: "batch"
    act: "relu"
    n_blocks: 14
    projection_head: true
    use_dilation: true

# Optimizer configuration
optimizer:
  name: "Adam"
  kwargs:
    lr: 0.001
    weight_decay: 0.0001

# Criterion configuration (for contrastive learning)
criterion:
  name: "ContrastiveLoss"
  kwargs:
    pos_margin: 0
    neg_margin: 1
    distance:
      function: "CosineSimilarity"

# Training parameters
training:
  validate_every: 1
  epochs: 50
  checkpoint_every: 1

# Scheduler configuration
scheduler:
  step_size: 15
  gamma: 0.5

# Wandb configuration
use_wandb: false
wandb_project: "Chromatin"
wandb_run_name: "shape_model_training"

output:
  checkpoint_dir: experiments/shape_model/checkpoints
  log_dir: experiments/shape_model/logs
  save_every: 5 