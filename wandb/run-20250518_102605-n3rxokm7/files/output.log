2025-05-18 10:26:06,433 [INFO] __main__: Initialized wandb for logging
2025-05-18 10:26:06,433 [INFO] __main__: Creating CustomShapeTrainer
2025-05-18 10:26:06,434 [INFO] dataloader.morphofeatures_adapter: Creating MorphoFeatures-compatible dataloader for root_dir: nuclei_sample_1a_v1
Total number of samples to process: 612
2025-05-18 10:26:06,672 [INFO] dataloader.morphofeatures_adapter: Created dataloader with 612 samples
2025-05-18 10:26:06,672 [INFO] dataloader.morphofeatures_adapter: Adapted dataloader for MorphoFeatures with 612 samples
2025-05-18 10:26:06,692 [INFO] dataloader.morphofeatures_adapter: Sample batch shapes:
2025-05-18 10:26:06,693 [INFO] dataloader.morphofeatures_adapter:   - points: torch.Size([2, 3, 1024])
2025-05-18 10:26:06,693 [INFO] dataloader.morphofeatures_adapter:   - features: torch.Size([2, 6, 1024])
2025-05-18 10:26:06,693 [INFO] dataloader.morphofeatures_adapter: âœ… Dataloader format compatible with MorphoFeatures
2025-05-18 10:26:06,693 [INFO] dataloader.morphofeatures_adapter: Creating MorphoFeatures-compatible dataloader for root_dir: nuclei_sample_1a_v1
Total number of samples to process: 612
2025-05-18 10:26:06,726 [INFO] dataloader.morphofeatures_adapter: Created dataloader with 612 samples
2025-05-18 10:26:06,726 [INFO] dataloader.morphofeatures_adapter: Adapted dataloader for MorphoFeatures with 612 samples
2025-05-18 10:26:06,727 [INFO] dataloader.morphofeatures_adapter: Sample batch shapes:
2025-05-18 10:26:06,727 [INFO] dataloader.morphofeatures_adapter:   - points: torch.Size([2, 3, 1024])
2025-05-18 10:26:06,728 [INFO] dataloader.morphofeatures_adapter:   - features: torch.Size([2, 6, 1024])
2025-05-18 10:26:06,728 [INFO] dataloader.morphofeatures_adapter: âœ… Dataloader format compatible with MorphoFeatures
2025-05-18 10:26:06,728 [INFO] __main__: Train dataset size: 612
2025-05-18 10:26:06,728 [INFO] __main__: Validation dataset size: 612
2025-05-18 10:26:07,723 [INFO] __main__: Starting training
2025-05-18 10:26:07,723 [INFO] __main__: Starting model training via fit()...
[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 306/306 [01:12<00:00,  4.19it/s]
2025-05-18 10:27:20,684 [INFO] __main__: Epoch 0 â†’ avg validation loss: 0.000000
2025-05-18 10:27:20,707 [INFO] __main__: New best validation loss: 0.000000
Training epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 306/306 [01:38<00:00,  3.10it/s]
2025-05-18 10:28:59,422 [INFO] __main__: Epoch 0 â†’ avg train loss: 0.109693â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 306/306 [01:38<00:00,  3.18it/s]
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 306/306 [00:51<00:00,  5.96it/s]
2025-05-18 10:29:50,811 [INFO] __main__: Epoch 0 â†’ avg validation loss: 0.000000â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 306/306 [00:51<00:00,  6.13it/s]
Training epoch 1:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                         | 59/306 [00:19<01:20,  3.06it/s]
Epochs:   2%|â–ˆâ–ˆâ–                                                                                                                     | 1/50 [02:49<2:18:22, 169.43s/it]
Traceback (most recent call last):
  File "train_morphofeatures_models.py", line 224, in run
    self.train()
  File "train_morphofeatures_models.py", line 208, in train
    self.train_epoch()
  File "train_morphofeatures_models.py", line 123, in train_epoch
    loss.backward()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
